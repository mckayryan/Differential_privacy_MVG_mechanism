{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas\n",
    "import numpy\n",
    "import glob\n",
    "import re\n",
    "\n",
    "# local imports\n",
    "from differential_privacy_parameters import get_query_point_sensitivity\n",
    "from differential_privacy_parameters import get_query_row_sensitivity\n",
    "from differential_privacy_parameters import get_query_gamma\n",
    "\n",
    "from differential_privacy_mechanisms import gaussian_mechanism_matrix_sample\n",
    "from differential_privacy_mechanisms import matrixvariate_gaussian_mechanism_sample\n",
    "from differential_privacy_mechanisms import MVGMechanism\n",
    "\n",
    "from model_evaluation import test_train_split\n",
    "from model_evaluation import principle_component_RSS\n",
    "from model_evaluation import root_mean_squared_error\n",
    "from model_evaluation import record_result\n",
    "\n",
    "from preprocessing import centered_sample_covariance_matrix\n",
    "from preprocessing import scale_data\n",
    "\n",
    "from models import seq_nn_single_evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Data Processing and Setup\n",
    "\n",
    "Import and concatonate all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading...\tdata/Florida_100000_20190227\n",
      "Loading...\tdata/Ohio_100000_20190227\n",
      "Loading...\tdata/Pennsylvania_100000_20190227\n",
      "Loading...\tdata/Illinois_100000_20190227\n",
      "Loading...\tdata/Texas_100000_20190227\n",
      "Loading...\tdata/California_100000_20190227\n",
      "Loading...\tdata/Georgia_100000_20190227\n",
      "Loading...\tdata/New York_100000_20190227\n"
     ]
    }
   ],
   "source": [
    "target_dir = 'data/'\n",
    "\n",
    "data_load = None\n",
    "for file_name in glob.glob(target_dir + '*'):\n",
    "    if not(re.search(r'\\.data$',file_name)):\n",
    "        print('Loading...\\t' + file_name)\n",
    "        if data_load is None:\n",
    "            data_load = pandas.read_pickle(file_name)\n",
    "        else:\n",
    "            data_load = pandas.concat([data_load,\n",
    "                                       pandas.read_pickle(file_name)], \n",
    "                                      sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_load.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale data and establish evaluation parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_samples = 100\n",
    "\n",
    "evaluation_features = [\n",
    "    'bmi',\n",
    "    'diastolic_blood_pressure',\n",
    "    'systolic_blood_pressure',\n",
    "    'glucose',\n",
    "    'hdl_cholesterol',\n",
    "    'ldl_cholesterol',\n",
    "    'total_cholesterol',\n",
    "    'triglycerides',\n",
    "    'age',\n",
    "    'framingham'    \n",
    "]\n",
    "\n",
    "data_feature_bounds = {\n",
    "    'bmi':(0,400),\n",
    "    'diastolic_blood_pressure':(60,140),\n",
    "    'systolic_blood_pressure':(90,250),\n",
    "    'glucose':(0,2000),\n",
    "    'hdl_cholesterol':(0,1500),\n",
    "    'ldl_cholesterol':(0,2000),\n",
    "    'total_cholesterol':(0,2100),\n",
    "    'triglycerides':(0,3000),\n",
    "    'age':(0,120),\n",
    "    'framingham':(-10,37)\n",
    "}\n",
    "target_feature_bounds = (0,1)\n",
    "\n",
    "# Setup for estimation of framingham score\n",
    "response = ['framingham']\n",
    "predictors = [ f for f in evaluation_features if f not in response]\n",
    "\n",
    "results_columns = [\n",
    "    'mechanism', \n",
    "    'query', \n",
    "    'iteration', \n",
    "    'metric', \n",
    "    'result', \n",
    "    'mechanism runtime (s)', \n",
    "    'total runtime (s)'\n",
    "]\n",
    "\n",
    "# Scale data 'data_feature_bounds' -> 'target_feature_bounds'\n",
    "data = scale_data(data_load[evaluation_features].dropna(),\n",
    "                  target_bounds=target_feature_bounds,\n",
    "                  data_bounds=data_feature_bounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Differential Privacy parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 1.0 \n",
    "# 1 / number of observations\n",
    "delta = pow(data.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of Sample Covariance Differential Privacy Methods\n",
    "\n",
    "## Gaussian Mechanism with symmetric and identity sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Symmetric Gaussian Mechanism\n",
    "\n",
    "Evaluation setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labelling result values for mechanism\n",
    "mechanism = 'gaussian'\n",
    "query_type = 'covariance'\n",
    "metric = 'principle component RSS'\n",
    "\n",
    "result_pickle_location = 'results/'\n",
    "result_pickle_name = '_'.join([mechanism, \n",
    "                               query_type, \n",
    "                               str(evaluation_samples), \n",
    "                               datetime.date.today().strftime(\"%Y%m%d\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Differential Privacy parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 1.0 \n",
    "# 1 / number of observations\n",
    "delta = pow(data.shape[0], -1)\n",
    "\n",
    "sensitivity = get_query_row_sensitivity(query_type='covariance',\n",
    "                                        query_scale=target_feature_bounds,\n",
    "                                        query_shape=data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation of symmetric matrix gaussian mechanism sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = centered_sample_covariance_matrix(X=data)\n",
    "\n",
    "result = None\n",
    "sample = dict()\n",
    "\n",
    "for i in xrange(evaluation_samples): \n",
    "    # Sample mechanism\n",
    "    start_clock = datetime.datetime.now()\n",
    "    # Add symmetric iid noise\n",
    "    sample[i] = gaussian_mechanism_matrix_sample(\n",
    "                data=query,\n",
    "                epsilon=epsilon,\n",
    "                delta=delta,\n",
    "                sensitivity=sensitivity,\n",
    "                symmetric=True,\n",
    "                verbose=False)\n",
    "    end_sample_clock = datetime.datetime.now() \n",
    "\n",
    "    result = record_result(results=result, \n",
    "                           column_names=results_columns, \n",
    "                           new_data=[[mechanism, \n",
    "                                      query_type, \n",
    "                                      i+1,\n",
    "                                      metric, \n",
    "                                      principle_component_RSS(true=query, pred=sample[i]), \n",
    "                                      (end_sample_clock - start_clock).total_seconds(),\n",
    "                                      (end_sample_clock - start_clock).total_seconds()\n",
    "                                     ]])\n",
    "    \n",
    "result.to_pickle(result_pickle_location + result_pickle_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identity Gaussian Mechanism\n",
    "\n",
    "Evaluation setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labelling result values for mechanism\n",
    "mechanism = 'gaussian'\n",
    "query_type = 'itentity'\n",
    "metric = 'principle component RSS'\n",
    "\n",
    "result_pickle_name = '_'.join([mechanism, \n",
    "                               query_type, \n",
    "                               str(evaluation_samples), \n",
    "                               datetime.date.today().strftime(\"%Y%m%d\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Differential Privacy parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivity = get_query_row_sensitivity(query_type='singleton',\n",
    "                                        query_scale=target_feature_bounds,\n",
    "                                        query_shape=data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation of identity query guassian mechanism sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = centered_sample_covariance_matrix(X=data)\n",
    "\n",
    "result = None\n",
    "\n",
    "for i in xrange(evaluation_samples): \n",
    "    # Sample mechanism\n",
    "    start_clock = datetime.datetime.now()\n",
    "    # Add symmetric iid noise\n",
    "    sample = gaussian_mechanism_matrix_sample(\n",
    "                data=query,\n",
    "                epsilon=epsilon,\n",
    "                delta=delta,\n",
    "                sensitivity=sensitivity,\n",
    "                symmetric=False,\n",
    "                verbose=False)\n",
    "    end_sample_clock = datetime.datetime.now() \n",
    "\n",
    "    sample_cov = centered_sample_covariance_matrix(X=sample)\n",
    "    end_loop_clock = datetime.datetime.now() \n",
    "    \n",
    "    result = record_result(results=result, \n",
    "                           column_names=results_columns, \n",
    "                           new_data=[[mechanism, \n",
    "                                      query_type, \n",
    "                                      i+1,\n",
    "                                      metric, \n",
    "                                      principle_component_RSS(true=query, pred=sample_cov), \n",
    "                                      (end_sample_clock - start_clock).total_seconds(),\n",
    "                                      (end_loop_clock - start_clock).total_seconds()\n",
    "                                     ]])\n",
    "    \n",
    "result.to_pickle(result_pickle_location + result_pickle_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Evaluation of Data Release Differential Privacy Methods\n",
    "\n",
    "## Gaussian and Matrixvariate Gaussian Mechanisms by regression task\n",
    "\n",
    "### Identity Query "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_obs, n_features = data.shape\n",
    "\n",
    "evaluation_test_split = 0.1\n",
    "evalaution_test_size = int(n_obs*evaluation_test_split)\n",
    "evaluation_train_size = n_obs - evalaution_test_size\n",
    "\n",
    "evaluation_samples = 2\n",
    "\n",
    "# Model parameters\n",
    "model_params = dict(epochs=5, batch_size=32, verbose=0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline\n",
    "\n",
    "Evaluation Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labelling result values for mechanism\n",
    "mechanism = 'baseline'\n",
    "query_type = 'identity'\n",
    "metric = 'rmse'\n",
    "\n",
    "result_pickle_name = '_'.join([mechanism, \n",
    "                               query_type,\n",
    "                               ''.join(response), \n",
    "                               str(evaluation_samples), \n",
    "                               datetime.date.today().strftime(\"%Y%m%d\")])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation of baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = None\n",
    "\n",
    "for i in xrange(evaluation_samples):\n",
    "    start_clock = datetime.datetime.now()\n",
    "    # Train model and evaluate prediction metric on holdout set   \n",
    "    metric_result = seq_nn_single_evaluation(train_data=data,\n",
    "                                             test_data=data,\n",
    "                                             test_holdout_p=evaluation_test_split,\n",
    "                                             X_labels=predictors,\n",
    "                                             y_label=response,\n",
    "                                             fit_params=model_params)\n",
    "    \n",
    "    end_loop_clock = datetime.datetime.now() \n",
    "    \n",
    "    result = record_result(results=result, \n",
    "                           column_names=results_columns, \n",
    "                           new_data=[[mechanism, \n",
    "                                      query_type, \n",
    "                                      i+1,\n",
    "                                      metric, \n",
    "                                      metric_result, \n",
    "                                      0,\n",
    "                                      (end_loop_clock - start_clock).total_seconds()\n",
    "                                     ]])\n",
    "    \n",
    "result.to_pickle(result_pickle_location + result_pickle_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.decsribe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Singleton Gaussian Mechanism\n",
    "\n",
    "Evaluation Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labelling result values for mechanism\n",
    "mechanism = 'gaussian'\n",
    "query_type = 'identity'\n",
    "metric = 'rmse'\n",
    "\n",
    "result_pickle_name = '_'.join([mechanism, \n",
    "                               query_type, \n",
    "                               ''.join(response),\n",
    "                               str(evaluation_samples), \n",
    "                               datetime.date.today().strftime(\"%Y%m%d\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Differential Privacy Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 1.0 \n",
    "# 1 / number of observations\n",
    "delta = pow(evaluation_train_size, -1)\n",
    "\n",
    "sensitivity = get_query_point_sensitivity(query_type='singleton',\n",
    "                                          query_scale=target_feature_bounds,\n",
    "                                          query_shape=(evaluation_train_size, n_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation of singleton gaussian sequential NN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = None\n",
    "\n",
    "for i in xrange(evaluation_samples):\n",
    "    \n",
    "    start_clock = datetime.datetime.now()\n",
    "    \n",
    "    train_ind, test_ind = \\\n",
    "            test_train_split(len(data),\n",
    "                             evaluation_test_split)\n",
    "        \n",
    "    sample = gaussian_mechanism_matrix_sample(\n",
    "        data=data.iloc[train_ind],\n",
    "        epsilon=epsilon,\n",
    "        delta=delta,\n",
    "        sensitivity=sensitivity,\n",
    "        symmetric=False,\n",
    "        verbose=False)\n",
    "    \n",
    "    end_sample_clock = datetime.datetime.now() \n",
    "        \n",
    "    # Train model and evaluate prediction metric on holdout set   \n",
    "    metric_result = seq_nn_single_evaluation(train_data=sample,\n",
    "                                             test_data=data,\n",
    "                                             X_labels=predictors,\n",
    "                                             y_label=response,\n",
    "                                             train_ind=train_ind, \n",
    "                                             test_ind=test_ind,\n",
    "                                             fit_params=model_params)\n",
    "    \n",
    "    end_loop_clock = datetime.datetime.now() \n",
    "    \n",
    "    result = record_result(results=result, \n",
    "                           column_names=results_columns, \n",
    "                           new_data=[[mechanism, \n",
    "                                      query_type, \n",
    "                                      i+1,\n",
    "                                      metric, \n",
    "                                      metric_result, \n",
    "                                      (end_sample_clock - start_clock).total_seconds(),\n",
    "                                      (end_loop_clock - start_clock).total_seconds()\n",
    "                                     ]])\n",
    "    \n",
    "result.to_pickle(result_pickle_location + result_pickle_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix-variate Gaussian Mechanism\n",
    "\n",
    "Binary Allocation Strategy - Key features\n",
    "   \n",
    "    key features = ['age','total_cholesterol','framingham'] \n",
    "    \n",
    "    'age' and 'cholesterol' important as contribute the largest scores to the total. \n",
    "    'framingham' important as the target variable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MVG_binary_knowledge_identity_framingham_2_20190227\n"
     ]
    }
   ],
   "source": [
    "# labelling result values for mechanism\n",
    "mechanism = 'MVG_binary_knowledge'\n",
    "query_type = 'identity'\n",
    "metric = 'rmse'\n",
    "\n",
    "result_pickle_name = '_'.join([mechanism, \n",
    "                               query_type, \n",
    "                               ''.join(response),\n",
    "                               str(evaluation_samples), \n",
    "                               datetime.date.today().strftime(\"%Y%m%d\")])\n",
    "\n",
    "print(result_pickle_name)\n",
    "\n",
    "model_params = dict(epochs=10, batch_size=16, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Differential Privacy Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivity = get_query_row_sensitivity(query_type='identity',\n",
    "                                        query_scale=target_feature_bounds,\n",
    "                                        query_shape=(evaluation_train_size, n_features))\n",
    "\n",
    "gamma = get_query_gamma(query_scale=target_feature_bounds, \n",
    "                        query_shape=(evaluation_train_size, n_features), \n",
    "                        query_type='identity')\n",
    "\n",
    "# Allocation percentages in 'key_features_allocation' to key features \n",
    "# and remainder to all other features\n",
    "key_features_binary_mvg = ['age','total_cholesterol','framingham']  \n",
    "key_features_allocation = [0.45,0.55,0.65,0.75,0.85,0.95]\n",
    "\n",
    "feature_allocations = dict()\n",
    "for allocation in key_features_allocation:\n",
    "    \n",
    "    feature_allocations[allocation] = [ \n",
    "        allocation / len(key_features_binary_mvg)\n",
    "        if feature in key_features_binary_mvg \n",
    "        else (1 - allocation) / (n_features - len(key_features_binary_mvg))\n",
    "        for feature in evaluation_features \n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrix-variate Gaussian Mechnaism Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = None \n",
    "\n",
    "for key, allocation in feature_allocations.items():\n",
    "    \n",
    "    params = dict(\n",
    "        epsilon=epsilon,\n",
    "        delta=delta,\n",
    "        sensitivity=sensitivity,\n",
    "        gamma=gamma,\n",
    "        precision_allocation=allocation,\n",
    "        precision_direction=numpy.identity(features),\n",
    "        covariance_direction='unimodal features',\n",
    "        covariance_method='binary'\n",
    "    )\n",
    "    \n",
    "    for i in xrange(evaluation_samples):\n",
    "        start_clock = datetime.datetime.now() \n",
    "        train_ind, test_ind = \\\n",
    "            test_train_split(len(data),\n",
    "                             evaluation_test_split)\n",
    "            \n",
    "        sample = matrixvariate_gaussian_mechanism_sample(data=data.iloc[train_ind],\n",
    "                                                         **params)\n",
    "        \n",
    "        end_sample_clock = datetime.datetime.now() \n",
    "        \n",
    "        metric_result = seq_nn_single_evaluation(train_data=sample,\n",
    "                                                test_data=data,\n",
    "                                                X_labels=predictors,\n",
    "                                                y_label=response,\n",
    "                                                train_ind=train_ind, \n",
    "                                                test_ind=test_ind,\n",
    "                                                fit_params=model_params)\n",
    "        \n",
    "        end_loop_clock = datetime.datetime.now() \n",
    "        \n",
    "        result = record_result(results=result, \n",
    "                               column_names=results_columns, \n",
    "                               new_data=[[mechanism + '_' + str(key), \n",
    "                                          query_type, \n",
    "                                          i+1,\n",
    "                                          metric, \n",
    "                                          metric_result, \n",
    "                                          (end_sample_clock - start_clock).total_seconds(),\n",
    "                                          (end_loop_clock - start_clock).total_seconds()\n",
    "                                         ]])\n",
    "        \n",
    "result.to_pickle(result_pickle_location + result_pickle_name)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binary Allocation Strategy - Key features\n",
    "   \n",
    "    Features allocations are proprotional to the singular values or explained directional variance\n",
    "    \n",
    "    Directions are equal to eigenvectors of the sample covariance. \n",
    "    These are the orthogonal primary axis of the variation in the sample covariance "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MVG_binary_directed_identity_framingham_2_20190227\n"
     ]
    }
   ],
   "source": [
    "# labelling result values for mechanism\n",
    "mechanism = 'MVG_binary_directed'\n",
    "query_type = 'identity'\n",
    "metric = 'rmse'\n",
    "\n",
    "result_pickle_name = '_'.join([mechanism, \n",
    "                               query_type, \n",
    "                               ''.join(response),\n",
    "                               str(evaluation_samples), \n",
    "                               datetime.date.today().strftime(\"%Y%m%d\")])\n",
    "\n",
    "print(result_pickle_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Differential Privacy parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DP SVD parameters\n",
    "svd_privacy_allocation = 0.2\n",
    "\n",
    "svd_sensitivity = get_query_row_sensitivity(query_type='covariance',\n",
    "                                            query_scale=target_feature_bounds,\n",
    "                                            query_shape=data.shape)\n",
    "\n",
    "# DP MVG parameters\n",
    "\n",
    "sensitivity = get_query_row_sensitivity(query_type='identity',\n",
    "                                        query_scale=target_feature_bounds,\n",
    "                                        query_shape=(evaluation_train_size, n_features))\n",
    "\n",
    "gamma = get_query_gamma(query_scale=target_feature_bounds, \n",
    "                        query_shape=(evaluation_train_size, n_features), \n",
    "                        query_type='identity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = centered_sample_covariance_matrix(X=data)\n",
    "\n",
    "result = None\n",
    "\n",
    "for i in xrange(evaluation_samples): \n",
    "\n",
    "    start_svd_clock = datetime.datetime.now()\n",
    "    \n",
    "    cov_sample = gaussian_mechanism_matrix_sample(\n",
    "                data=query,\n",
    "                epsilon=epsilon*svd_privacy_allocation,\n",
    "                delta=delta*svd_privacy_allocation,\n",
    "                sensitivity=svd_sensitivity,\n",
    "                symmetric=True,\n",
    "                verbose=False)\n",
    "\n",
    "    precision_directions, singular_values, _ = numpy.linalg.svd(cov_sample, full_matrices=True)\n",
    "\n",
    "    sv_proportions = singular_values / numpy.sum(singular_values)\n",
    "    sv_allocations = [0.55,0.75,0.95]\n",
    "\n",
    "    feature_allocations = dict()\n",
    "    for allocation in sv_allocations:\n",
    "        feature_allocations[allocation] = [ \n",
    "            ((1 - allocation) / len(sv_proportions)) + \n",
    "            (sv * allocation)\n",
    "            for sv in sv_proportions\n",
    "        ]    \n",
    "\n",
    "    end_svd_clock = datetime.datetime.now()\n",
    "    \n",
    "    for key, allocation in feature_allocations.items():\n",
    "\n",
    "        start_mvg_clock = datetime.datetime.now()\n",
    "        params = dict(\n",
    "            epsilon=epsilon*(1.0-svd_privacy_allocation),\n",
    "            delta=delta*(1.0-svd_privacy_allocation),\n",
    "            sensitivity=sensitivity,\n",
    "            gamma=gamma,\n",
    "            precision_allocation=allocation,\n",
    "            precision_direction=precision_directions,\n",
    "            covariance_direction='unimodal features',\n",
    "            covariance_method='binary'\n",
    "        )\n",
    "\n",
    "        \n",
    "         \n",
    "        train_ind, test_ind = \\\n",
    "            test_train_split(len(data),\n",
    "                             evaluation_test_split)\n",
    "\n",
    "        sample = matrixvariate_gaussian_mechanism_sample(data=data.iloc[train_ind],\n",
    "                                                         **params)\n",
    "\n",
    "        end_mvg_clock = datetime.datetime.now() \n",
    "\n",
    "        metric_result = seq_nn_single_evaluation(train_data=sample,\n",
    "                                                 test_data=data,\n",
    "                                                 X_labels=predictors,\n",
    "                                                 y_label=response,\n",
    "                                                 train_ind=train_ind, \n",
    "                                                 test_ind=test_ind,\n",
    "                                                 fit_params=model_params)\n",
    "\n",
    "        end_loop_clock = datetime.datetime.now() \n",
    "        \n",
    "        sample_clock_dif = (end_svd_clock - start_svd_clock) + (end_mvg_clock - start_mvg_clock)\n",
    "        total_clock_dif =  (end_loop_clock - end_mvg_clock) + sample_clock_dif\n",
    "        \n",
    "        result = record_result(results=result, \n",
    "                               column_names=results_columns, \n",
    "                               new_data=[[mechanism + '_' + str(key), \n",
    "                                          query_type, \n",
    "                                          i+1,\n",
    "                                          metric, \n",
    "                                          metric_result, \n",
    "                                          sample_clock_dif.total_seconds(),\n",
    "                                          total_clock_dif.total_seconds()\n",
    "                                         ]])\n",
    "\n",
    "result.to_pickle(result_pickle_location + result_pickle_name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
