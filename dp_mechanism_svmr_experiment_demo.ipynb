{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thundersvmScikit import SVR\n",
    "\n",
    "import sklearn.metrics\n",
    "\n",
    "import datetime\n",
    "import pandas\n",
    "import numpy\n",
    "import glob\n",
    "import re\n",
    "from random import uniform\n",
    "\n",
    "\n",
    "from preprocessing import scale_data\n",
    "from preprocessing import centered_sample_covariance_matrix\n",
    "\n",
    "from differential_privacy_parameters import get_query_point_sensitivity\n",
    "from differential_privacy_parameters import get_query_row_sensitivity\n",
    "from differential_privacy_parameters import get_query_gamma\n",
    "\n",
    "from differential_privacy_mechanisms import gaussian_mechanism_matrix_sample\n",
    "from differential_privacy_mechanisms import matrixvariate_gaussian_mechanism_sample\n",
    "from differential_privacy_mechanisms import MVGMechanism\n",
    "\n",
    "from model_evaluation import record_result\n",
    "from model_evaluation import test_train_split\n",
    "\n",
    "from models import svr_parameter_tuning\n",
    "\n",
    "from metrics import mean_absolute_error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Data Processing and Setup\n",
    "\n",
    "Import and concatonate all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dir = 'data/'\n",
    "\n",
    "data_load = None\n",
    "for file_name in glob.glob(target_dir + '*'):\n",
    "    if not(re.search(r'\\.data$',file_name)):\n",
    "        print('Loading...\\t' + file_name)\n",
    "        if data_load is None:\n",
    "            data_load = pandas.read_pickle(file_name)\n",
    "        else:\n",
    "            data_load = pandas.concat([data_load,\n",
    "                                       pandas.read_pickle(file_name)], \n",
    "                                      sort=False)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_load.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_features = [\n",
    "    'bmi',\n",
    "    'diastolic_blood_pressure',\n",
    "    'systolic_blood_pressure',\n",
    "    'glucose',\n",
    "    'hdl_cholesterol',\n",
    "    'ldl_cholesterol',\n",
    "    'total_cholesterol',\n",
    "    'triglycerides',\n",
    "    'age',\n",
    "    'framingham'    \n",
    "]\n",
    "\n",
    "data_feature_bounds = {\n",
    "    'bmi':(0,400),\n",
    "    'diastolic_blood_pressure':(60,140),\n",
    "    'systolic_blood_pressure':(90,250),\n",
    "    'glucose':(0,2000),\n",
    "    'hdl_cholesterol':(0,1500),\n",
    "    'ldl_cholesterol':(0,2000),\n",
    "    'total_cholesterol':(0,2100),\n",
    "    'triglycerides':(0,3000),\n",
    "    'age':(0,120),\n",
    "    'framingham':(-10,37)\n",
    "}\n",
    "target_feature_bounds = (0,1)\n",
    "\n",
    "response = ['framingham']\n",
    "predictors = [ f for f in evaluation_features if f not in response]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing\n",
    "### Scaling and Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results/SVMR_15_100000_global_sensitivity_20190302\n"
     ]
    }
   ],
   "source": [
    "# Sample data if needed\n",
    "sample_size = 100000\n",
    "\n",
    "pickle_file = 'results/SVMR_15_' + str(sample_size) + '_global_sensitivity_20190302'\n",
    "print(pickle_file)\n",
    "\n",
    "# Scale data 'data_feature_bounds' -> 'target_feature_bounds'\n",
    "if isinstance(sample_size, int) and sample_size < len(data_load):\n",
    "    data = (scale_data(data_load[evaluation_features].dropna(),\n",
    "                      target_bounds=target_feature_bounds,\n",
    "                      data_bounds=data_feature_bounds)\n",
    "            .sample(sample_size))\n",
    "else:\n",
    "    data = scale_data(data_load[evaluation_features].dropna(),\n",
    "                      target_bounds=target_feature_bounds,\n",
    "                      data_bounds=data_feature_bounds)      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimental Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data', (69994, 10), 'training', 57249, 'test', 12749, 'tuning', 15000]\n"
     ]
    }
   ],
   "source": [
    "n_obs, n_features = data.shape\n",
    "\n",
    "evaluations = 25\n",
    "\n",
    "# Set aside data for hyperparameter tuning\n",
    "hyper_param_tuning_split = 0.15\n",
    "hyper_param_tuning_size = int(sample_size*hyper_param_tuning_split)\n",
    "hp_data = data.sample(hyper_param_tuning_size)\n",
    "\n",
    "test_split = 0.15\n",
    "test_size = int(n_obs*test_split)\n",
    "train_size = (n_obs - hyper_param_tuning_size) - test_size\n",
    "\n",
    "# Remove tuning data to create train/test set\n",
    "data = data[~data.set_index(evaluation_features)\n",
    "             .index\n",
    "             .isin(hp_data\n",
    "                   .set_index(evaluation_features)\n",
    "                   .index)]\n",
    "\n",
    "X = data[predictors].values\n",
    "y = data[response].values\n",
    "\n",
    "recorded_results = None\n",
    "results_columns = [\n",
    "    'query',\n",
    "    'mechanism',\n",
    "    'metric',\n",
    "    'result',\n",
    "    'sample size',\n",
    "    'mechanism runtime (s)',\n",
    "    'iteration',\n",
    "    'sensitivity type',\n",
    "    'sensitivity',\n",
    "    'epsilon',\n",
    "    'delta',\n",
    "    'gamma',\n",
    "    'training size',\n",
    "    'test holdout size',\n",
    "    'tuning holdout size',\n",
    "    'model',\n",
    "    'kernel',\n",
    "    'global min',\n",
    "    'global max',\n",
    "    'response min',\n",
    "    'response max',\n",
    "    'response',\n",
    "    'predictors'   \n",
    "]\n",
    "\n",
    "print(['data', data.shape, \n",
    "      'training', train_size, \n",
    "      'test', test_size, \n",
    "      'tuning', len(hp_data)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Evaluation of Data Release Differential Privacy Methods\n",
    "\n",
    "## Gaussian and Matrixvariate Gaussian Mechanisms by Regression Experiments\n",
    "\n",
    "### Identity Query \n",
    "\n",
    "### Support Vector Machine Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean Baseline Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(evaluations):\n",
    "\n",
    "    train_ind, test_ind = test_train_split(y_len=len(y), test_perc=test_split)\n",
    "    \n",
    "    result = [\n",
    "        mean_absolute_error(y[test_ind], \n",
    "                            [numpy.mean(y[train_ind])]*len(test_ind), 200)\n",
    "    ]\n",
    "    \n",
    "    to_record = {\n",
    "        'query':'none',\n",
    "        'mechanism':'mean',\n",
    "        'metric':'MAE',\n",
    "        'result':result,\n",
    "        'sample size':sample_size,\n",
    "        'mechanism runtime (s)':0,\n",
    "        'iteration':i,\n",
    "        'sensitivity type':'none',\n",
    "        'sensitivity':0,\n",
    "        'epsilon':0,\n",
    "        'delta':0,\n",
    "        'gamma':0,\n",
    "        'training size':train_size,\n",
    "        'test holdout size':test_size,\n",
    "        'tuning holdout size':hyper_param_tuning_size,\n",
    "        'model':'SVM Regression',\n",
    "        'kernel':'rbf',\n",
    "        'global min':target_feature_bounds[0],\n",
    "        'global max':target_feature_bounds[1],\n",
    "        'response min':min(y[test_ind]),\n",
    "        'response max':max(y[test_ind]),\n",
    "        'response':response,\n",
    "        'predictors': ' '.join(predictors)\n",
    "    }\n",
    "    recorded_results = \\\n",
    "        record_result(results=recorded_results, \n",
    "                      new_data=to_record,\n",
    "                      column_names=results_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unprivatised Data \n",
    "\n",
    "Baseline Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "params = svr_parameter_tuning(\n",
    "    X=hp_data[predictors].values,\n",
    "    y=hp_data[response].values,\n",
    "    scoring_function=mean_absolute_error,\n",
    "    rand_iters=200,\n",
    "    search_range=(0.001,4.0),\n",
    "    holdout_split=0.2,\n",
    "    kernel='rbf')\n",
    "\n",
    "for i in range(evaluations):\n",
    "    \n",
    "    train_ind, test_ind = test_train_split(y_len=len(y), test_perc=test_split)\n",
    "    \n",
    "    model = SVR(kernel='rbf', C=params['best_C'], gamma=params['best_gamma'])\n",
    "    model.fit(X[train_ind], y[train_ind].ravel())\n",
    "\n",
    "    result = [\n",
    "        mean_absolute_error(y[test_ind], \n",
    "                            model.predict(X[test_ind]).reshape(-1,1), \n",
    "                            100)\n",
    "    ]\n",
    "    \n",
    "    to_record = {\n",
    "        'query':'none',\n",
    "        'mechanism':'baseline',\n",
    "        'metric':'MAE',\n",
    "        'result':result,\n",
    "        'sample size':sample_size,\n",
    "        'mechanism runtime (s)':0,\n",
    "        'iteration':i,\n",
    "        'sensitivity type':'none',\n",
    "        'sensitivity':0,\n",
    "        'epsilon':0,\n",
    "        'delta':0,\n",
    "        'gamma':0,\n",
    "        'training size':train_size,\n",
    "        'test holdout size':test_size,\n",
    "        'tuning holdout size':hyper_param_tuning_size,\n",
    "        'model':'SVM Regression',\n",
    "        'kernel':'rbf',\n",
    "        'global min':target_feature_bounds[0],\n",
    "        'global max':target_feature_bounds[1],\n",
    "        'response min':min(y[test_ind]),\n",
    "        'repsonse max':max(y[test_ind]),\n",
    "        'response':response,\n",
    "        'predictors': ' '.join(predictors)\n",
    "    }\n",
    "    \n",
    "    recorded_results = \\\n",
    "        record_result(results=recorded_results, \n",
    "                      new_data=to_record,\n",
    "                      column_names=results_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "recorded_results[recorded_results['mechanism'] == 'baseline']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iid Gaussian Matrix Mechanism \n",
    "\n",
    "Baseline Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.0, 1.429e-05, 1)\n"
     ]
    }
   ],
   "source": [
    "# differential privacy parameters\n",
    "epsilon = 1.0 \n",
    "# 1 / number of observations\n",
    "delta = pow(train_size, -1)\n",
    "\n",
    "sensitivity = get_query_point_sensitivity(query_type='identity',\n",
    "                                          query_scale=target_feature_bounds,\n",
    "                                          query_shape=(train_size, n_features))\n",
    "\n",
    "print(epsilon, round(delta, 8), sensitivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.534689\n"
     ]
    }
   ],
   "source": [
    "privacy_params = dict(\n",
    "    epsilon=epsilon,\n",
    "    delta=delta,\n",
    "    sensitivity=sensitivity,    \n",
    "    symmetric=False,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "params = svr_parameter_tuning(\n",
    "    X=hp_data[predictors].values,\n",
    "    y=hp_data[response].values,\n",
    "    scoring_function=mean_absolute_error,\n",
    "    rand_iters=200,\n",
    "    search_range=(0.001,4.0),\n",
    "    holdout_split=0.2,\n",
    "    kernel='rbf',\n",
    "    privacy_mechanism_sampler=gaussian_mechanism_matrix_sample,\n",
    "    privacy_mechanism_params=privacy_params,\n",
    "    privacy_sample_iterations=5)\n",
    "\n",
    "\n",
    "for i in range(evaluations):\n",
    "  \n",
    "    train_ind, test_ind = test_train_split(y_len=len(data), \n",
    "                                           test_perc=test_split)\n",
    "    \n",
    "    start_clock = datetime.datetime.now()\n",
    "    sample_gaus = gaussian_mechanism_matrix_sample(\n",
    "            data=data.iloc[train_ind],\n",
    "            **privacy_params)\n",
    "    end_clock = datetime.datetime.now()\n",
    "    \n",
    "    model = SVR(kernel='rbf', C=params['best_C'], gamma=params['best_gamma'])\n",
    "    model.fit(sample_gaus[predictors].values, \n",
    "              sample_gaus[response].values)\n",
    "    \n",
    "    result = [\n",
    "        mean_absolute_error(y[test_ind], \n",
    "                            model.predict(X[test_ind]).reshape(-1,1), \n",
    "                            100)\n",
    "    ] \n",
    "    \n",
    "    to_record = {\n",
    "        'query':'singleton',\n",
    "        'mechanism':'matrix iid gaussian',\n",
    "        'metric':'MAE',\n",
    "        'result':result,\n",
    "        'sample size':sample_size,\n",
    "        'mechanism runtime (s)':(end_clock - start_clock).total_seconds(),\n",
    "        'iteration':i,\n",
    "        'sensitivity type':'global',\n",
    "        'sensitivity':sensitivity,\n",
    "        'epsilon':epsilon,\n",
    "        'delta':delta,\n",
    "        'gamma':0,\n",
    "        'training size':train_size,\n",
    "        'test holdout size':test_size,\n",
    "        'tuning holdout size':hyper_param_tuning_size,\n",
    "        'model':'SVM Regression',\n",
    "        'kernel':'rbf',\n",
    "        'global min':target_feature_bounds[0],\n",
    "        'global max':target_feature_bounds[1],\n",
    "        'response min':min(y[test_ind]),\n",
    "        'response max':max(y[test_ind]),\n",
    "        'response':response,\n",
    "        'predictors': ' '.join(predictors)\n",
    "    }\n",
    "    \n",
    "    recorded_results = \\\n",
    "        record_result(results=recorded_results, \n",
    "                      new_data=to_record,\n",
    "                      column_names=results_columns)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "recorded_results[recorded_results['mechanism'] == 'matrix iid gaussian']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrix-variate Gaussian Mechanism\n",
    "\n",
    "Binary Allocation Strategy Key features\n",
    "   \n",
    "    key features = ['age','total_cholesterol','framingham'] \n",
    "    \n",
    "    'age' and 'cholesterol' important as contribute the largest scores to the total. \n",
    "    'framingham' important as the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3.1622776601683795, 836.6600265340755)\n"
     ]
    }
   ],
   "source": [
    "# MVG mechanism privacy parameters\n",
    "sensitivity = get_query_row_sensitivity(query_scale=target_feature_bounds,\n",
    "                                        query_shape=(train_size, n_features),\n",
    "                                        query_type='identity')\n",
    "\n",
    "gamma = get_query_gamma(query_scale=target_feature_bounds, \n",
    "                        query_shape=(train_size, n_features), \n",
    "                        query_type='identity')\n",
    "\n",
    "\n",
    "# Allocation percentages in 'key_features_allocation' to key features \n",
    "# and remainder to all other features\n",
    "key_features_binary_mvg = ['age','total_cholesterol','framingham']  \n",
    "key_features_allocation =[0.65, 0.7, 0.75, 0.80, 0.85]\n",
    "\n",
    "feature_allocations = dict()\n",
    "\n",
    "for allocation in key_features_allocation:\n",
    "    \n",
    "    feature_allocations['mvg '+str(allocation)] = [ \n",
    "        allocation / len(key_features_binary_mvg)\n",
    "        if feature in key_features_binary_mvg \n",
    "        else (1 - allocation) / (n_features - len(key_features_binary_mvg))\n",
    "        for feature in evaluation_features \n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.086958\n",
      "1.945335\n",
      "2.06515\n",
      "1.928468\n",
      "2.01048\n"
     ]
    }
   ],
   "source": [
    "for key, allocation in feature_allocations.items():\n",
    "    \n",
    "    privacy_params_mvg = dict(\n",
    "        epsilon=epsilon,\n",
    "        delta=delta,\n",
    "        sensitivity=sensitivity,\n",
    "        gamma=gamma,\n",
    "        precision_allocation=allocation,\n",
    "        precision_direction=numpy.identity(n_features),\n",
    "        covariance_direction='unimodal features',\n",
    "        covariance_method='binary'\n",
    "    )\n",
    "    \n",
    "    params = svr_parameter_tuning(\n",
    "        X=hp_data[predictors].values,\n",
    "        y=hp_data[response].values,\n",
    "        scoring_function=mean_absolute_error,\n",
    "        rand_iters=200,\n",
    "        search_range=(0.001,4.0),\n",
    "        holdout_split=0.2,\n",
    "        kernel='rbf',\n",
    "        privacy_mechanism_sampler=matrixvariate_gaussian_mechanism_sample,\n",
    "        privacy_mechanism_params=privacy_params_mvg,\n",
    "        privacy_sample_iterations=5)\n",
    "    \n",
    "    for i in range(evaluations):\n",
    "        \n",
    "        start_clock = datetime.datetime.now()\n",
    "        train_ind, test_ind = test_train_split(y_len=len(data), \n",
    "                                           test_perc=test_split)\n",
    "    \n",
    "        sample_mvg = matrixvariate_gaussian_mechanism_sample(\n",
    "            data=data.iloc[train_ind],\n",
    "            **privacy_params_mvg)\n",
    "\n",
    "        end_clock = datetime.datetime.now()\n",
    "\n",
    "        model = SVR(kernel='rbf', C=params['best_C'], gamma=params['best_gamma'])\n",
    "        model.fit(sample_mvg[predictors], sample_mvg[response])\n",
    "\n",
    "        result = [\n",
    "            mean_absolute_error(y[test_ind], \n",
    "                                model.predict(X[test_ind]).reshape(-1,1), \n",
    "                                100)\n",
    "        ]     \n",
    "       \n",
    "        to_record = {\n",
    "            'query':'identity',\n",
    "            'mechanism':key,\n",
    "            'metric':'MAE',\n",
    "            'result':result,\n",
    "            'sample size':sample_size,\n",
    "            'mechanism runtime (s)':(end_clock - start_clock).total_seconds(),\n",
    "            'iteration':i,\n",
    "            'sensitivity type':'global',\n",
    "            'sensitivity':sensitivity,\n",
    "            'epsilon':epsilon,\n",
    "            'delta':delta,\n",
    "            'gamma':gamma,\n",
    "            'training size':train_size,\n",
    "            'test holdout size':test_size,\n",
    "            'tuning holdout size':hyper_param_tuning_size,\n",
    "            'model':'SVM Regression',\n",
    "            'kernel':'rbf',\n",
    "            'global min':target_feature_bounds[0],\n",
    "            'global max':target_feature_bounds[1],\n",
    "            'response min':min(y[test_ind]),\n",
    "            'response max':max(y[test_ind]),\n",
    "            'response':response,\n",
    "            'predictors': ' '.join(predictors)\n",
    "        }\n",
    "        \n",
    "        recorded_results = \\\n",
    "            record_result(results=recorded_results, \n",
    "                          new_data=to_record,\n",
    "                          column_names=results_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "recorded_results[recorded_results['mechanism'].str.startswith('mvg', na=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrix-variate Gaussian Mechanism\n",
    "\n",
    "Derived Directional Noise\n",
    "\n",
    "Features allocations are proprotional to the singular values or explained directional variance\n",
    "    \n",
    "    Directions are equal to eigenvectors of the sample covariance. \n",
    "    These are the orthogonal primary axis of the variation in the sample covariance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3.1622776601683795, 836.6600265340755)\n",
      "0.00023529965411\n"
     ]
    }
   ],
   "source": [
    "# DP SVD parameters\n",
    "svd_privacy_allocation = 0.15\n",
    "\n",
    "svd_sensitivity = get_query_row_sensitivity(query_type='covariance',\n",
    "                                            query_scale=target_feature_bounds,\n",
    "                                            query_shape=data.shape)\n",
    "\n",
    "# DP MVG parameters\n",
    "\n",
    "sensitivity = get_query_row_sensitivity(query_type='identity',\n",
    "                                        query_scale=target_feature_bounds,\n",
    "                                        query_shape=(train_size, n_features))\n",
    "\n",
    "gamma = get_query_gamma(query_scale=target_feature_bounds, \n",
    "                        query_shape=(train_size, n_features), \n",
    "                        query_type='identity')\n",
    "\n",
    "print(sensitivity, gamma)  \n",
    "print(svd_sensitivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.117705\n",
      "1.970278\n",
      "1.911625\n",
      "1.884837\n",
      "1.952032\n"
     ]
    }
   ],
   "source": [
    "# Allocation percentages in 'key_features_allocation' to key features \n",
    "# and remainder to all other features \n",
    "sv_allocations = [0.65, 0.7, 0.75, 0.80, 0.85]\n",
    "\n",
    "tuning_query = centered_sample_covariance_matrix(X=hp_data)\n",
    "\n",
    "for key in sv_allocations:\n",
    "    \n",
    "    start_svd_clock = datetime.datetime.now()\n",
    "    cov_sample = gaussian_mechanism_matrix_sample(\n",
    "                data=tuning_query,\n",
    "                epsilon=epsilon*svd_privacy_allocation,\n",
    "                delta=delta*svd_privacy_allocation,\n",
    "                sensitivity=svd_sensitivity,\n",
    "                symmetric=True,\n",
    "                verbose=False)\n",
    "\n",
    "    precision_directions, singular_values, _ = numpy.linalg.svd(cov_sample, full_matrices=True)\n",
    "\n",
    "    sv_proportions = singular_values / numpy.sum(singular_values)\n",
    "        \n",
    "    feature_allocations = dict()\n",
    "    for allocation in sv_allocations:\n",
    "        feature_allocations[key] = [ \n",
    "            ((1 - allocation) / len(sv_proportions)) + \n",
    "            (sv * allocation)\n",
    "            for sv in sv_proportions\n",
    "        ] \n",
    "    end_svd_clock = datetime.datetime.now()\n",
    "    \n",
    "    privacy_params_mvg = dict(\n",
    "        epsilon=epsilon,\n",
    "        delta=delta,\n",
    "        sensitivity=sensitivity,\n",
    "        gamma=gamma,\n",
    "        precision_allocation=feature_allocations[key],\n",
    "        precision_direction=precision_directions,\n",
    "        covariance_direction='unimodal features',\n",
    "        covariance_method='binary'\n",
    "    )\n",
    "    \n",
    "    params = svr_parameter_tuning(\n",
    "        X=hp_data[predictors].values,\n",
    "        y=hp_data[response].values,\n",
    "        scoring_function=mean_absolute_error,\n",
    "        rand_iters=200,\n",
    "        search_range=(0.001,4.0),\n",
    "        holdout_split=0.2,\n",
    "        kernel='rbf',\n",
    "        privacy_mechanism_sampler=matrixvariate_gaussian_mechanism_sample,\n",
    "        privacy_mechanism_params=privacy_params_mvg,\n",
    "        privacy_sample_iterations=5)\n",
    "    \n",
    "    for i in range(evaluations):\n",
    "        \n",
    "        start_clock = datetime.datetime.now()\n",
    "        train_ind, test_ind = test_train_split(y_len=len(data), \n",
    "                                           test_perc=test_split)\n",
    "        \n",
    "        sample_mvg = matrixvariate_gaussian_mechanism_sample(\n",
    "            data=data.iloc[train_ind],\n",
    "            **privacy_params_mvg)\n",
    "\n",
    "        end_clock = datetime.datetime.now()\n",
    "\n",
    "        model = SVR(kernel='rbf', C=params['best_C'], gamma=params['best_gamma'])\n",
    "        model.fit(sample_mvg[predictors], sample_mvg[response])\n",
    "\n",
    "        result = [\n",
    "            mean_absolute_error(y[test_ind], \n",
    "                                model.predict(X[test_ind]).reshape(-1,1), \n",
    "                                100)\n",
    "        ]     \n",
    "        \n",
    "        sample_clock_dif = (end_svd_clock - start_svd_clock) + (end_clock - start_clock)\n",
    "       \n",
    "        to_record = {\n",
    "            'query':'identity',\n",
    "            'mechanism':'mvg directed ' + str(key),\n",
    "            'metric':'MAE',\n",
    "            'result':result,\n",
    "            'sample size':sample_size,\n",
    "            'mechanism runtime (s)':sample_clock_dif.total_seconds(),\n",
    "            'iteration':i,\n",
    "            'sensitivity type':'global',\n",
    "            'sensitivity':sensitivity,\n",
    "            'epsilon':epsilon,\n",
    "            'delta':delta,\n",
    "            'gamma':gamma,\n",
    "            'training size':train_size,\n",
    "            'test holdout size':test_size,\n",
    "            'tuning holdout size':hyper_param_tuning_size,\n",
    "            'model':'SVM Regression',\n",
    "            'kernel':'rbf',\n",
    "            'global min':target_feature_bounds[0],\n",
    "            'global max':target_feature_bounds[1],\n",
    "            'response min':min(y[test_ind]),\n",
    "            'response max':max(y[test_ind]),\n",
    "            'response':response,\n",
    "            'predictors': ' '.join(predictors)\n",
    "        }\n",
    "        \n",
    "        recorded_results = \\\n",
    "            record_result(results=recorded_results, \n",
    "                          new_data=to_record,\n",
    "                          column_names=results_columns)\n",
    "    \n",
    "    print((end_clock - start_clock).total_seconds())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recorded_results[recorded_results['mechanism'].str.startswith('mvg directed', na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "recorded_results.to_pickle(pickle_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
