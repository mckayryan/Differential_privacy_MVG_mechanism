{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import pandas\n",
    "import math \n",
    "import pprint\n",
    "\n",
    "from framingham10yr.framingham10yr import framingham_10year_risk\n",
    "\n",
    "\n",
    "# Local imports\n",
    "from calculate_framingham_risk_score import calculate_framingham_risk_score\n",
    "\n",
    "import preprocessing\n",
    "from preprocessing import scale_data\n",
    "from preprocessing import centered_sample_covariance_matrix\n",
    "\n",
    "import differential_privacy_mechanisms\n",
    "from differential_privacy_mechanisms import gaussian_mechanism\n",
    "from differential_privacy_mechanisms import gaussian_mechanism_matrix_sample\n",
    "\n",
    "from differential_privacy_mechanisms import MVGMechanism\n",
    "from differential_privacy_mechanisms import centered_covariance_query_sensitivity\n",
    "\n",
    "import model_evaluation\n",
    "from model_evaluation import principle_component_RSS\n",
    "from model_evaluation import root_mean_squared_error\n",
    "\n",
    "# My Utility Scripts\n",
    "# from printd import printd\n",
    "# from plots import plot_curves\n",
    "# from plots import plot_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_key = [\n",
    "    'date',\n",
    "    'encounter',\n",
    "    'patient',    \n",
    "]\n",
    "\n",
    "new_num_features = [\n",
    "    'bmi',\n",
    "    'diastolic_blood_pressure',\n",
    "    'systolic_blood_pressure',\n",
    "    'glucose',\n",
    "    'hdl_cholesterol',\n",
    "    'ldl_cholesterol',\n",
    "    'total_cholesterol',\n",
    "    'triglycerides',\n",
    "    'age',\n",
    "    'framingham'\n",
    "]\n",
    "\n",
    "new_cat_features = [\n",
    "    'sex',\n",
    "    'smoker',\n",
    "    'blood_pressure_med_treatment'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import process_synthea_patient_data\n",
    "from process_synthea_patient_data import process_synthea_patient_data\n",
    "\n",
    "data_location = 'synthea/output/csv/'\n",
    "target_dir = 'data/'\n",
    "target_file_name = 'Florida_100000_20190227' \n",
    "# + datetime.date.today().strftime(\"%Y%m%d\")\n",
    "\n",
    "# data = process_synthea_patient_data(data_dir=data_location,\n",
    "#                                     data_save_dir=target_dir,\n",
    "#                                     data_save_name=target_file_name).describe()\n",
    "\n",
    "# data = pandas.read_pickle(target_dir+target_file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bmi</th>\n",
       "      <th>diastolic_blood_pressure</th>\n",
       "      <th>systolic_blood_pressure</th>\n",
       "      <th>glucose</th>\n",
       "      <th>hdl_cholesterol</th>\n",
       "      <th>ldl_cholesterol</th>\n",
       "      <th>total_cholesterol</th>\n",
       "      <th>triglycerides</th>\n",
       "      <th>age</th>\n",
       "      <th>framingham</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>180760.000000</td>\n",
       "      <td>180760.000000</td>\n",
       "      <td>180760.000000</td>\n",
       "      <td>180760.000000</td>\n",
       "      <td>180760.000000</td>\n",
       "      <td>180760.000000</td>\n",
       "      <td>180760.000000</td>\n",
       "      <td>180760.000000</td>\n",
       "      <td>180760.000000</td>\n",
       "      <td>180760.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>35.407962</td>\n",
       "      <td>88.490405</td>\n",
       "      <td>137.443018</td>\n",
       "      <td>89.580627</td>\n",
       "      <td>63.520117</td>\n",
       "      <td>98.072879</td>\n",
       "      <td>192.645247</td>\n",
       "      <td>151.715086</td>\n",
       "      <td>54.758556</td>\n",
       "      <td>10.569263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.007346</td>\n",
       "      <td>13.445424</td>\n",
       "      <td>26.793899</td>\n",
       "      <td>23.388825</td>\n",
       "      <td>13.512145</td>\n",
       "      <td>27.857323</td>\n",
       "      <td>27.445294</td>\n",
       "      <td>68.380698</td>\n",
       "      <td>11.852553</td>\n",
       "      <td>5.442565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>17.300000</td>\n",
       "      <td>67.400000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>36.450000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>50.900000</td>\n",
       "      <td>160.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>20.889802</td>\n",
       "      <td>-6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>31.500000</td>\n",
       "      <td>77.900000</td>\n",
       "      <td>116.300000</td>\n",
       "      <td>74.600000</td>\n",
       "      <td>59.900000</td>\n",
       "      <td>78.500000</td>\n",
       "      <td>173.000000</td>\n",
       "      <td>116.100000</td>\n",
       "      <td>46.053388</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>83.500000</td>\n",
       "      <td>127.700000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>66.500000</td>\n",
       "      <td>91.400000</td>\n",
       "      <td>186.000000</td>\n",
       "      <td>132.100000</td>\n",
       "      <td>56.095825</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>38.700000</td>\n",
       "      <td>100.200000</td>\n",
       "      <td>161.000000</td>\n",
       "      <td>95.700000</td>\n",
       "      <td>73.200000</td>\n",
       "      <td>108.350000</td>\n",
       "      <td>198.900000</td>\n",
       "      <td>147.900000</td>\n",
       "      <td>64.301164</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>254.800000</td>\n",
       "      <td>123.500000</td>\n",
       "      <td>200.900000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>305.000000</td>\n",
       "      <td>528.800000</td>\n",
       "      <td>78.806297</td>\n",
       "      <td>26.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 bmi  diastolic_blood_pressure  systolic_blood_pressure  \\\n",
       "count  180760.000000             180760.000000            180760.000000   \n",
       "mean       35.407962                 88.490405               137.443018   \n",
       "std         6.007346                 13.445424                26.793899   \n",
       "min        17.300000                 67.400000                97.000000   \n",
       "25%        31.500000                 77.900000               116.300000   \n",
       "50%        35.000000                 83.500000               127.700000   \n",
       "75%        38.700000                100.200000               161.000000   \n",
       "max       254.800000                123.500000               200.900000   \n",
       "\n",
       "             glucose  hdl_cholesterol  ldl_cholesterol  total_cholesterol  \\\n",
       "count  180760.000000    180760.000000    180760.000000      180760.000000   \n",
       "mean       89.580627        63.520117        98.072879         192.645247   \n",
       "std        23.388825        13.512145        27.857323          27.445294   \n",
       "min        36.450000        20.000000        50.900000         160.000000   \n",
       "25%        74.600000        59.900000        78.500000         173.000000   \n",
       "50%        85.000000        66.500000        91.400000         186.000000   \n",
       "75%        95.700000        73.200000       108.350000         198.900000   \n",
       "max       200.000000        80.000000       200.000000         305.000000   \n",
       "\n",
       "       triglycerides            age     framingham  \n",
       "count  180760.000000  180760.000000  180760.000000  \n",
       "mean      151.715086      54.758556      10.569263  \n",
       "std        68.380698      11.852553       5.442565  \n",
       "min       100.000000      20.889802      -6.000000  \n",
       "25%       116.100000      46.053388       8.000000  \n",
       "50%       132.100000      56.095825      12.000000  \n",
       "75%       147.900000      64.301164      14.000000  \n",
       "max       528.800000      78.806297      26.000000  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[new_num_features].dropna().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Preprocess data\n",
    "    # establish bounds\n",
    "    # centre and scale (bounds -> [-1,1])    \n",
    "\n",
    "# Gathered from anecdotal internet sources\n",
    "# We require reasonable lower and upper bounds on values for Global Sensitivity calculation\n",
    "bounds = {\n",
    "    'bmi':(0,200),\n",
    "    'diastolic_blood_pressure':(60,140),\n",
    "    'systolic_blood_pressure':(90,250),\n",
    "    'glucose':(0,1000),\n",
    "    'hdl_cholesterol':(0,400),\n",
    "    'ldl_cholesterol':(0,1000),\n",
    "    'total_cholesterol':(0,1500),\n",
    "    'triglycerides':(0,3000),\n",
    "    'age':(0,120),\n",
    "    'framingham':(-10,37)\n",
    "}\n",
    "\n",
    "feature_scale = (-1,1)\n",
    "results = dict()\n",
    "\n",
    "X = scale_data(data=data[new_num_features].dropna(), data_bounds=bounds, target_bounds=feature_scale)\n",
    "\n",
    "obs, features = X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DP COVARIANCE ESTIMATION - SIMPLE GAUSSIAN NOISE TO COVARIANCE ESTIMATION QUERY\n",
    "# Add symmetric noise to covariance matrix estimate f(X) = (1/n)*transpose(X)X\n",
    "\n",
    "# Compute sample correlation\n",
    "query = centered_sample_covariance_matrix(X=X)\n",
    "\n",
    "# Add symmetric iid noise\n",
    "sample_symmetric = gaussian_mechanism_matrix_sample(\n",
    "            data=query,\n",
    "            epsilon=epsilon,\n",
    "            delta=delta,\n",
    "            sensitivity=symmetric_unit_sensitivity,\n",
    "            symmetric=True,\n",
    "            verbose=False)\n",
    "\n",
    "print('Symmetric Sample')\n",
    "print([principle_component_RSS(true=query, pred=s) for s in sample_symmetric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DP COVARIANCE ESTIMATION - SIMPLE GAUSSIAN NOISE TO IDENTITY QUERY \n",
    "# Add noise to scaled dataset f(X) = X\n",
    "sample_identity = gaussian_mechanism_matrix_sample(\n",
    "    data=X,\n",
    "    epsilon=epsilon,\n",
    "    delta=delta,\n",
    "    sensitivity=unit_sensitivity,\n",
    "    symmetric=False,\n",
    "    verbose=False)\n",
    "\n",
    "# Compute sample covariance\n",
    "sample_identity_cov = centered_sample_covariance_matrix(X=sample_identity)\n",
    "\n",
    "print('Identity Sample')\n",
    "print(principle_component_RSS(true=query, pred=sample_identity_cov))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup for estimation of framingham score\n",
    "y_name = ['framingham']\n",
    "X_names = [ f for f in new_num_features if not(f=='framingham')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DP DATA RELEASE - BASELINE MODEL ON UNPRIVATISED DATA\n",
    "# Create sequential NN model\n",
    "results['baseline'] = list()\n",
    "\n",
    "nn_fit_params = dict(epochs=10, batch_size=16, verbose=0) \n",
    "\n",
    "results['baseline'] = \\\n",
    "    seq_nn_cross_validation(train_data=X, \n",
    "                            test_data=X, \n",
    "                            folds=10,\n",
    "                            X_labels=X_names,\n",
    "                            y_label=y_name,\n",
    "                            fit_params=nn_fit_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint.pprint(results['baseline'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DP DATA RELEASE - SIMPLE GAUSSIAN NOISE TO IDENTITY QUERY \n",
    "# Generate differentially private sample from simple Gaussian Mechanism\n",
    "X_gaus_dp = gaussian_mechanism_matrix_sample(\n",
    "    data=X,\n",
    "    epsilon=epsilon,\n",
    "    delta=delta,\n",
    "    sensitivity=unit_sensitivity,\n",
    "    symmetric=False,\n",
    "    verbose=False)\n",
    "\n",
    "nn_fit_params = dict(\n",
    "    epochs=10, \n",
    "    batch_size=16,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "results['gaussian'] = \\\n",
    "    seq_nn_cross_validation(train_data=X_gaus_dp, \n",
    "                            test_data=X, \n",
    "                            folds=5,\n",
    "                            X_labels=X_names,\n",
    "                            y_label=y_name,\n",
    "                            fit_params=nn_fit_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint.pprint(results['gaussian'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DP COVARIANCE ESTIMATION - MATRIX-VARIATE GAUSSIAN (MVG) NOISE TO IDENTITY QUERY \n",
    "# Generate differentially private sample from Matrix-variate Gaussian mechanism\n",
    "'''\n",
    "    Binary Allocation Strategy\n",
    "    \n",
    "    key features = ['age','total_cholesterol','framingham'] \n",
    "    \n",
    "    'age' and 'cholesterol' important as contribute the largest scores to the total. \n",
    "    'framingham' important as the target variable.\n",
    "'''\n",
    "\n",
    "results['mvg binary allocation'] = dict()\n",
    "\n",
    "# Allocation percentages in 'key_features_allocation' to key features \n",
    "# and remainder to all other features\n",
    "key_features_binary_mvg = ['age','total_cholesterol','framingham']  \n",
    "key_features_allocation = [0.45,0.55,0.65,0.75,0.85,0.95]\n",
    "\n",
    "feature_allocations = dict()\n",
    "for allocation in key_features_allocation:\n",
    "    feature_allocations[allocation] = [ \n",
    "        allocation / len(key_features_binary_mvg)\n",
    "        if feature in key_features_binary_mvg \n",
    "        else (1 - allocation) / (features - len(key_features_binary_mvg))\n",
    "        for feature in new_num_features \n",
    "    ]\n",
    "    \n",
    "    params = dict(\n",
    "        epsilon=epsilon,\n",
    "        delta=delta,\n",
    "        sensitivity=obs_sensitivity,\n",
    "        gamma=gamma,\n",
    "        precision_allocation=feature_allocations[allocation],\n",
    "        precision_direction=numpy.identity(features),\n",
    "        covariance_direction='unimodal features',\n",
    "        covariance_method='binary'\n",
    "    )\n",
    "\n",
    "    X_mvg_sdp = matrixvariate_gaussian_mechanism_sample(data=X,\n",
    "                                                        **params)\n",
    "    nn_fit_params = dict(\n",
    "        epochs=10, \n",
    "        batch_size=16,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    results['mvg binary allocation'][allocation] = \\\n",
    "        seq_nn_cross_validation(train_data=X_mvg_sdp, \n",
    "                                test_data=X, \n",
    "                                folds=5,\n",
    "                                X_labels=X_names,\n",
    "                                y_label=y_name,\n",
    "                                fit_params=nn_fit_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['mvg binary allocation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Binary Allocation Strategy\n",
    "    \n",
    "    Features allocations are proprotional to the singular values or explained directional variance\n",
    "    \n",
    "    Directions are equal to eigenvectors of the sample covariance. \n",
    "    These are the orthogonal primary axis of the variation in the sample covariance \n",
    "'''\n",
    "\n",
    "results['mvg directed binary allocation'] = dict()\n",
    "\n",
    "dp_sample_cov = gaussian_mechanism_matrix_sample(\n",
    "            data=query,\n",
    "            epsilon=epsilon*0.2,\n",
    "            delta=delta*0.2,\n",
    "            sensitivity=symmetric_unit_sensitivity,\n",
    "            symmetric=True,\n",
    "            verbose=False)\n",
    "\n",
    "Q, XX_sv, Qt = numpy.linalg.svd(dp_sample_cov, full_matrices=True)\n",
    "\n",
    "sv_proportion = XX_sv / numpy.sum(XX_sv)\n",
    "sv_allocation = [0.55,0.75,0.95]\n",
    "\n",
    "feature_allocations = dict()\n",
    "for allocation in sv_allocation:\n",
    "    feature_allocations[allocation] = [ \n",
    "        ((1 - allocation) / len(sv_proportion)) + \n",
    "        (sv*allocation)\n",
    "        for sv in sv_proportion\n",
    "    ]\n",
    "    \n",
    "    params = dict(\n",
    "        epsilon=epsilon,\n",
    "        delta=delta,\n",
    "        sensitivity=obs_sensitivity,\n",
    "        gamma=gamma,\n",
    "        precision_allocation=feature_allocations[allocation],\n",
    "        precision_direction=Q,\n",
    "        covariance_direction='unimodal features',\n",
    "        covariance_method='binary'\n",
    "    )\n",
    "\n",
    "    X_mvg_sdp = matrixvariate_gaussian_mechanism_sample(data=X,\n",
    "                                                        **params)\n",
    "    nn_fit_params = dict(\n",
    "        epochs=10, \n",
    "        batch_size=16,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    results['mvg directed binary allocation'][allocation] = \\\n",
    "        seq_nn_cross_validation(train_data=X_mvg_sdp, \n",
    "                                test_data=X, \n",
    "                                folds=5,\n",
    "                                X_labels=X_names,\n",
    "                                y_label=y_name,\n",
    "                                fit_params=nn_fit_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['mvg directed binary allocation']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
